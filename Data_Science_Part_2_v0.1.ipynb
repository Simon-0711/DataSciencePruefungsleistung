{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 2\n",
    "\n",
    "Matrikelnummern: 1679412\n",
    "\n",
    "Folgende Regressionsarten werden verwendet um eine vorhersage das SalePrices zu erstellen:\n",
    "* Lineare Regression\n",
    "* RandomForest\n",
    "* ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0, 2, 3, 8, 10, 11]\n",
      "[1, 4, 5, 6, 7, 9, 12, 13, 14, 15]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "E:\\Programme\\Python\\Python36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:778: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mE:\\Programme\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'neg_root_mean_squared_error'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-77cab43f789f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mregressionTypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Regression Type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'R2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RMSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MAPE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MAX'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-204-77cab43f789f>\u001b[0m in \u001b[0;36mcalc_regression\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     36\u001b[0m     scores = cross_validate(pipe, x,y, cv=5, scoring=['r2', 'neg_mean_squared_error', \n\u001b[0;32m     37\u001b[0m                                                       \u001b[1;34m'neg_root_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'neg_median_absolute_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                                                       'max_error' ])\n\u001b[0m\u001b[0;32m     39\u001b[0m     return {'R2': scores['r2'].mean(), 'MSE': scores['neg_mean_squared_error'], \n\u001b[0;32m     40\u001b[0m             \u001b[1;34m'RMSE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'neg_root_mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MAPE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'neg_median_absolute_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                          % repr(scoring))\n\u001b[0;32m    379\u001b[0m                 scorers = {scorer: check_scoring(estimator, scoring=scorer)\n\u001b[1;32m--> 380\u001b[1;33m                            for scorer in scoring}\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                 raise ValueError(err_msg +\n",
      "\u001b[1;32mE:\\Programme\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                          % repr(scoring))\n\u001b[0;32m    379\u001b[0m                 scorers = {scorer: check_scoring(estimator, scoring=scorer)\n\u001b[1;32m--> 380\u001b[1;33m                            for scorer in scoring}\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                 raise ValueError(err_msg +\n",
      "\u001b[1;32mE:\\Programme\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    270\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    230\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0;32m    231\u001b[0m                              \u001b[1;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                              'to get valid options.' % (scoring))\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'neg_root_mean_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ],
     "ename": "ValueError",
     "evalue": "'neg_root_mean_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "output_type": "error"
    }
   ],
   "source": [
    "# read a specific column from a csv file\n",
    "def read_data(path):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    return df\n",
    "\n",
    "# scaling numerical values and turning objects into numerical values\n",
    "def scale_and_convert_columns(df, model):\n",
    "    categoricalCols = []\n",
    "    for i in range(len(df.columns)):\n",
    "        if (df.dtypes[i] == object):\n",
    "            categoricalCols.append(i)\n",
    "    numericalCols = []\n",
    "    for i in range(len(df.columns)):\n",
    "        if (df.dtypes[i] == 'int64' ):\n",
    "            numericalCols.append(i)        \n",
    "            \n",
    "    print(categoricalCols)\n",
    "    print(numericalCols)\n",
    "    \n",
    "    preprocessor = make_column_transformer((categoricalCols, OneHotEncoder(handle_unknown='ignore')),\n",
    "                                            (numericalCols, RobustScaler()))\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', model)])\n",
    "    return pipe\n",
    "    #return pd.get_dummies(df, columns=categoricalCols)\n",
    "\n",
    "# calculates R2, MSE, RMSE, MAPE and MAX* for the given regression model\n",
    "def  calc_regression(model):\n",
    "    df = read_data('SetFiltered.csv')\n",
    "    pipe = scale_and_convert_columns(df.drop('SalePrice', axis=1), model)\n",
    "    \n",
    "    x = df.drop('SalePrice', axis=1).values #dimensions\n",
    "    y = df['SalePrice'].values #prediction\n",
    "    \n",
    "    # neg_root_mean_squared_error and neg_median_absolute_error somehow don't work\n",
    "    scores = cross_validate(pipe, x,y, cv=5, scoring=['r2', 'neg_mean_squared_error', \n",
    "                                                      'neg_root_mean_squared_error', 'neg_median_absolute_error', \n",
    "                                                      'max_error' ])\n",
    "    return {'R2': scores['r2'].mean(), 'MSE': scores['neg_mean_squared_error'], \n",
    "            'RMSE': np.sqrt(scores['neg_root_mean_squared_error']), 'MAPE': scores['neg_median_absolute_error'], \n",
    "            'MAX': scores['max_error'].mean()*-1}\n",
    "\n",
    "#calculate the score for each model\n",
    "regressionTypes = [LinearRegression()]\n",
    "results = []\n",
    "for r in regressionTypes:\n",
    "    results.append(calc_regression(r))\n",
    "\n",
    "df = pd.DataFrame(data=results, columns=['Regression Type', 'R2', 'MSE', 'RMSE', 'MAPE', 'MAX'])\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}